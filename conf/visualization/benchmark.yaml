# @package visualization
# Benchmark visualization configuration - absolute minimal overhead

# Core visualization settings
debug_level: "off"
enabled: false  # Completely disabled for pure benchmarking

# If enabled, use absolute minimal settings
output_formats: ["svg"]
image_quality: "low"
output_dir: "outputs/benchmark"

# No visual enhancements
show_coordinates: false
show_operation_names: false
highlight_changes: false
include_metrics: false
color_scheme: "default"

# No episode visualization
visualize_episodes: false
episode_summaries: false
step_visualizations: false

# No logging during benchmark
log_frequency: 0  # Never log
log_episode_end: false
log_episode_start: false
log_key_moments: false

# Disable all expensive features
enable_comparisons: false
save_intermediate_states: false

# Minimal memory usage
lazy_loading: true
memory_limit_mb: 50
max_storage_gb: 0.1

# No async processing
async_processing:
  enabled: false
  queue_size: 0
  worker_threads: 0
  batch_size: 1
  flush_interval: 0

# Minimal episode management
episode_management:
  base_output_dir: "outputs/benchmark"
  run_name: "benchmark"
  episode_dir_format: "ep_{episode:03d}"
  step_file_format: "step_{step:02d}"
  max_episodes_per_run: 10
  cleanup_policy: "immediate"

# No performance monitoring (to avoid overhead)
performance_monitoring:
  enabled: false
  target_overhead: 0.0
  measurement_window: 1
  auto_adjust: false

# No wandb for pure benchmarking
wandb:
  enabled: false
  project_name: "jaxarc-benchmark"
  tags: ["benchmark", "performance"]
  log_frequency: 0
  offline_mode: true
  image_format: "png"
  max_image_size: [400, 300]